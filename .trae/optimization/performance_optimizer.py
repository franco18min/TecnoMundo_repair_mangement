#!/usr/bin/env python3
"""
‚ö° NEXUS - Performance Optimizer
Optimizador de rendimiento integral para m√°xima eficiencia
TecnoMundo Repair Management - Trae 2.0
"""

import json
import time
import psutil
import logging
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from pathlib import Path
from collections import defaultdict, deque
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
import numpy as np

@dataclass
class PerformanceMetrics:
    """M√©tricas de rendimiento del sistema"""
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    disk_io: Dict[str, float]
    network_io: Dict[str, float]
    response_time: float
    throughput: float
    error_rate: float
    cache_hit_rate: float
    token_efficiency: float

@dataclass
class OptimizationStrategy:
    """Estrategia de optimizaci√≥n"""
    strategy_id: str
    strategy_type: str
    target_metric: str
    expected_improvement: float
    implementation_cost: float
    priority: int
    conditions: List[str]
    actions: List[Dict[str, Any]]
    success_criteria: Dict[str, float]

@dataclass
class OptimizationResult:
    """Resultado de optimizaci√≥n aplicada"""
    optimization_id: str
    strategy_used: str
    metrics_before: PerformanceMetrics
    metrics_after: PerformanceMetrics
    improvement_achieved: float
    side_effects: List[str]
    execution_time: float
    success: bool
    timestamp: datetime

class PerformanceOptimizer:
    """Optimizador de rendimiento integral"""
    
    def __init__(self, config_dir: str = ".trae/optimization"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(parents=True, exist_ok=True)
        
        # Archivos de configuraci√≥n
        self.config_file = self.config_dir / "performance_config.json"
        self.metrics_file = self.config_dir / "performance_metrics.json"
        self.optimizations_file = self.config_dir / "optimization_history.json"
        
        # Estado del sistema
        self.current_metrics: Optional[PerformanceMetrics] = None
        self.metrics_history: deque = deque(maxlen=1000)
        self.optimization_strategies: Dict[str, OptimizationStrategy] = {}
        self.optimization_history: List[OptimizationResult] = []
        
        # Configuraci√≥n de optimizaci√≥n
        self.optimization_config = {
            "monitoring_interval": 30,  # segundos
            "auto_optimization": True,
            "optimization_threshold": {
                "cpu_usage": 80.0,
                "memory_usage": 85.0,
                "response_time": 5.0,
                "error_rate": 0.05,
                "token_efficiency": 0.7
            },
            "optimization_targets": {
                "response_time_target": 2.0,
                "memory_usage_target": 70.0,
                "cpu_usage_target": 60.0,
                "token_efficiency_target": 0.9,
                "cache_hit_rate_target": 0.85
            }
        }
        
        # Estrategias de optimizaci√≥n predefinidas
        self._initialize_optimization_strategies()
        
        # Sistema de monitoreo
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # M√©tricas de optimizaci√≥n
        self.optimization_stats = {
            "total_optimizations": 0,
            "successful_optimizations": 0,
            "average_improvement": 0.0,
            "total_time_saved": 0.0,
            "total_tokens_saved": 0,
            "system_uptime": 0.0
        }
        
        # Configurar logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Cargar configuraci√≥n existente
        self._load_configuration()
        
        # Iniciar monitoreo autom√°tico
        self.start_monitoring()
    
    def start_monitoring(self):
        """Inicia el monitoreo continuo de rendimiento"""
        
        if not self.monitoring_active:
            self.monitoring_active = True
            self.monitoring_thread = threading.Thread(
                target=self._monitoring_loop,
                daemon=True
            )
            self.monitoring_thread.start()
            self.logger.info("üìä Monitoreo de rendimiento iniciado")
    
    def stop_monitoring(self):
        """Detiene el monitoreo de rendimiento"""
        
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        self.logger.info("üìä Monitoreo de rendimiento detenido")
    
    def collect_metrics(self) -> PerformanceMetrics:
        """Recolecta m√©tricas actuales del sistema"""
        
        try:
            # M√©tricas del sistema
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk_io = psutil.disk_io_counters()._asdict() if psutil.disk_io_counters() else {}
            network_io = psutil.net_io_counters()._asdict() if psutil.net_io_counters() else {}
            
            # M√©tricas espec√≠ficas de la aplicaci√≥n
            response_time = self._measure_response_time()
            throughput = self._calculate_throughput()
            error_rate = self._calculate_error_rate()
            cache_hit_rate = self._calculate_cache_hit_rate()
            token_efficiency = self._calculate_token_efficiency()
            
            metrics = PerformanceMetrics(
                timestamp=datetime.now(),
                cpu_usage=cpu_percent,
                memory_usage=memory.percent,
                disk_io=disk_io,
                network_io=network_io,
                response_time=response_time,
                throughput=throughput,
                error_rate=error_rate,
                cache_hit_rate=cache_hit_rate,
                token_efficiency=token_efficiency
            )
            
            self.current_metrics = metrics
            self.metrics_history.append(metrics)
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"Error recolectando m√©tricas: {e}")
            return self._get_default_metrics()
    
    def analyze_performance(self, time_window_minutes: int = 30) -> Dict[str, Any]:
        """Analiza el rendimiento en una ventana de tiempo"""
        
        try:
            # Filtrar m√©tricas por ventana de tiempo
            cutoff_time = datetime.now() - timedelta(minutes=time_window_minutes)
            recent_metrics = [
                m for m in self.metrics_history
                if m.timestamp > cutoff_time
            ]
            
            if not recent_metrics:
                return {
                    "success": False,
                    "reason": "No hay m√©tricas en la ventana de tiempo especificada"
                }
            
            # Calcular estad√≠sticas
            stats = self._calculate_performance_statistics(recent_metrics)
            
            # Identificar tendencias
            trends = self._identify_performance_trends(recent_metrics)
            
            # Detectar anomal√≠as
            anomalies = self._detect_performance_anomalies(recent_metrics)
            
            # Identificar cuellos de botella
            bottlenecks = self._identify_bottlenecks(recent_metrics)
            
            # Calcular score de salud del sistema
            health_score = self._calculate_system_health_score(recent_metrics)
            
            # Generar recomendaciones
            recommendations = self._generate_performance_recommendations(
                stats, trends, anomalies, bottlenecks
            )
            
            analysis = {
                "analysis_period": f"{time_window_minutes} minutos",
                "metrics_analyzed": len(recent_metrics),
                "performance_statistics": stats,
                "performance_trends": trends,
                "anomalies_detected": anomalies,
                "bottlenecks_identified": bottlenecks,
                "system_health_score": health_score,
                "recommendations": recommendations,
                "optimization_opportunities": self._identify_optimization_opportunities(
                    stats, trends, bottlenecks
                )
            }
            
            self.logger.info(f"üìà An√°lisis completado - Salud del sistema: {health_score:.2f}")
            return analysis
            
        except Exception as e:
            self.logger.error(f"Error en an√°lisis de rendimiento: {e}")
            return {"success": False, "error": str(e)}
    
    def optimize_performance(self, target_metrics: Optional[Dict[str, float]] = None) -> Dict[str, Any]:
        """Optimiza el rendimiento del sistema"""
        
        try:
            # Usar m√©tricas objetivo por defecto si no se especifican
            if not target_metrics:
                target_metrics = self.optimization_config["optimization_targets"]
            
            # Recolectar m√©tricas actuales
            current_metrics = self.collect_metrics()
            
            # Identificar estrategias de optimizaci√≥n aplicables
            applicable_strategies = self._identify_applicable_strategies(current_metrics, target_metrics)
            
            if not applicable_strategies:
                return {
                    "success": True,
                    "message": "Sistema ya optimizado - no se requieren cambios",
                    "current_metrics": asdict(current_metrics)
                }
            
            # Priorizar estrategias por impacto esperado
            prioritized_strategies = self._prioritize_strategies(applicable_strategies, current_metrics)
            
            # Aplicar optimizaciones
            optimization_results = []
            total_improvement = 0.0
            
            for strategy in prioritized_strategies[:5]:  # Aplicar m√°ximo 5 estrategias
                result = self._apply_optimization_strategy(strategy, current_metrics)
                optimization_results.append(result)
                
                if result.success:
                    total_improvement += result.improvement_achieved
                    self.optimization_stats["successful_optimizations"] += 1
                
                self.optimization_stats["total_optimizations"] += 1
            
            # Recolectar m√©tricas despu√©s de optimizaci√≥n
            final_metrics = self.collect_metrics()
            
            # Calcular mejora total
            overall_improvement = self._calculate_overall_improvement(current_metrics, final_metrics)
            
            # Actualizar estad√≠sticas
            self.optimization_stats["average_improvement"] = (
                (self.optimization_stats["average_improvement"] * 
                 (self.optimization_stats["total_optimizations"] - len(optimization_results)) +
                 total_improvement) / self.optimization_stats["total_optimizations"]
            )
            
            optimization_summary = {
                "success": True,
                "optimizations_applied": len(optimization_results),
                "successful_optimizations": sum(1 for r in optimization_results if r.success),
                "total_improvement": overall_improvement,
                "metrics_before": asdict(current_metrics),
                "metrics_after": asdict(final_metrics),
                "optimization_details": [asdict(r) for r in optimization_results],
                "performance_gain": self._calculate_performance_gain(current_metrics, final_metrics),
                "estimated_time_saved": self._estimate_time_saved(overall_improvement),
                "next_optimization_recommendations": self._generate_next_optimization_recommendations(final_metrics)
            }
            
            self.logger.info(f"‚ö° Optimizaci√≥n completada - Mejora total: {overall_improvement:.2f}%")
            return optimization_summary
            
        except Exception as e:
            self.logger.error(f"Error en optimizaci√≥n: {e}")
            return {"success": False, "error": str(e)}
    
    def auto_tune_system(self) -> Dict[str, Any]:
        """Ajuste autom√°tico del sistema basado en patrones de uso"""
        
        try:
            # Analizar patrones de uso hist√≥ricos
            usage_patterns = self._analyze_usage_patterns()
            
            # Identificar configuraciones √≥ptimas
            optimal_configs = self._identify_optimal_configurations(usage_patterns)
            
            # Aplicar ajustes autom√°ticos
            tuning_results = []
            
            for config_name, config_value in optimal_configs.items():
                result = self._apply_configuration_change(config_name, config_value)
                tuning_results.append(result)
            
            # Optimizar cach√© autom√°ticamente
            cache_optimization = self._optimize_cache_configuration(usage_patterns)
            
            # Ajustar l√≠mites de recursos
            resource_optimization = self._optimize_resource_limits(usage_patterns)
            
            # Configurar monitoreo adaptativo
            monitoring_optimization = self._optimize_monitoring_configuration(usage_patterns)
            
            tuning_summary = {
                "configurations_tuned": len(tuning_results),
                "successful_tunings": sum(1 for r in tuning_results if r.get("success", False)),
                "cache_optimization": cache_optimization,
                "resource_optimization": resource_optimization,
                "monitoring_optimization": monitoring_optimization,
                "usage_patterns_analyzed": usage_patterns,
                "tuning_details": tuning_results,
                "expected_performance_improvement": self._calculate_expected_tuning_improvement(tuning_results),
                "rollback_plan": self._generate_rollback_plan(tuning_results)
            }
            
            self.logger.info(f"üéõÔ∏è Auto-tuning completado - {len(tuning_results)} configuraciones ajustadas")
            return tuning_summary
            
        except Exception as e:
            self.logger.error(f"Error en auto-tuning: {e}")
            return {"success": False, "error": str(e)}
    
    def get_optimization_insights(self) -> Dict[str, Any]:
        """Obtiene insights de optimizaci√≥n del sistema"""
        
        # Calcular m√©tricas de rendimiento
        performance_score = self._calculate_performance_score()
        
        # Analizar tendencias de optimizaci√≥n
        optimization_trends = self._analyze_optimization_trends()
        
        # Identificar oportunidades de mejora
        improvement_opportunities = self._identify_improvement_opportunities()
        
        # Calcular ROI de optimizaciones
        optimization_roi = self._calculate_optimization_roi()
        
        # Generar predicciones de rendimiento
        performance_predictions = self._generate_performance_predictions()
        
        return {
            "system_overview": {
                "current_performance_score": performance_score,
                "total_optimizations": self.optimization_stats["total_optimizations"],
                "success_rate": (
                    self.optimization_stats["successful_optimizations"] / 
                    max(self.optimization_stats["total_optimizations"], 1)
                ),
                "average_improvement": self.optimization_stats["average_improvement"]
            },
            "current_metrics": asdict(self.current_metrics) if self.current_metrics else None,
            "optimization_trends": optimization_trends,
            "improvement_opportunities": improvement_opportunities,
            "optimization_roi": optimization_roi,
            "performance_predictions": performance_predictions,
            "system_recommendations": self._generate_system_recommendations(),
            "health_indicators": self._get_health_indicators()
        }
    
    # M√©todos auxiliares
    
    def _monitoring_loop(self):
        """Loop principal de monitoreo"""
        
        while self.monitoring_active:
            try:
                # Recolectar m√©tricas
                metrics = self.collect_metrics()
                
                # Verificar si se necesita optimizaci√≥n autom√°tica
                if self.optimization_config["auto_optimization"]:
                    if self._should_auto_optimize(metrics):
                        self.logger.info("üîÑ Iniciando optimizaci√≥n autom√°tica...")
                        self.optimize_performance()
                
                # Esperar intervalo de monitoreo
                time.sleep(self.optimization_config["monitoring_interval"])
                
            except Exception as e:
                self.logger.error(f"Error en loop de monitoreo: {e}")
                time.sleep(5)  # Esperar antes de reintentar
    
    def _should_auto_optimize(self, metrics: PerformanceMetrics) -> bool:
        """Determina si se debe ejecutar optimizaci√≥n autom√°tica"""
        
        thresholds = self.optimization_config["optimization_threshold"]
        
        return (
            metrics.cpu_usage > thresholds["cpu_usage"] or
            metrics.memory_usage > thresholds["memory_usage"] or
            metrics.response_time > thresholds["response_time"] or
            metrics.error_rate > thresholds["error_rate"] or
            metrics.token_efficiency < thresholds["token_efficiency"]
        )
    
    def _measure_response_time(self) -> float:
        """Mide el tiempo de respuesta promedio"""
        
        # Simular medici√≥n de tiempo de respuesta
        # En implementaci√≥n real, medir√≠a tiempos de API/UI
        return np.random.normal(2.5, 0.5)
    
    def _calculate_throughput(self) -> float:
        """Calcula el throughput del sistema"""
        
        # Simular c√°lculo de throughput
        # En implementaci√≥n real, contar√≠a requests/operaciones por segundo
        return np.random.normal(100, 20)
    
    def _calculate_error_rate(self) -> float:
        """Calcula la tasa de errores"""
        
        # Simular c√°lculo de tasa de errores
        # En implementaci√≥n real, analizar√≠a logs de errores
        return np.random.beta(1, 20)  # Sesgado hacia valores bajos
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calcula la tasa de aciertos de cach√©"""
        
        # Simular c√°lculo de cache hit rate
        # En implementaci√≥n real, analizar√≠a estad√≠sticas de cach√©
        return np.random.beta(8, 2)  # Sesgado hacia valores altos
    
    def _calculate_token_efficiency(self) -> float:
        """Calcula la eficiencia de tokens"""
        
        # Simular c√°lculo de eficiencia de tokens
        # En implementaci√≥n real, analizar√≠a uso vs resultados
        return np.random.beta(7, 3)  # Sesgado hacia valores altos
    
    def _initialize_optimization_strategies(self):
        """Inicializa estrategias de optimizaci√≥n predefinidas"""
        
        strategies = [
            {
                "strategy_id": "cache_optimization",
                "strategy_type": "cache",
                "target_metric": "response_time",
                "expected_improvement": 30.0,
                "implementation_cost": 2.0,
                "priority": 1,
                "conditions": ["cache_hit_rate < 0.8", "response_time > 3.0"],
                "actions": [
                    {"type": "increase_cache_size", "value": "50%"},
                    {"type": "optimize_cache_keys", "strategy": "lru"},
                    {"type": "preload_frequent_data", "threshold": 0.7}
                ],
                "success_criteria": {"cache_hit_rate": 0.85, "response_time": 2.5}
            },
            {
                "strategy_id": "memory_optimization",
                "strategy_type": "memory",
                "target_metric": "memory_usage",
                "expected_improvement": 25.0,
                "implementation_cost": 3.0,
                "priority": 2,
                "conditions": ["memory_usage > 80.0"],
                "actions": [
                    {"type": "garbage_collection", "aggressive": True},
                    {"type": "optimize_data_structures", "target": "large_objects"},
                    {"type": "implement_lazy_loading", "threshold": "1MB"}
                ],
                "success_criteria": {"memory_usage": 70.0}
            },
            {
                "strategy_id": "cpu_optimization",
                "strategy_type": "cpu",
                "target_metric": "cpu_usage",
                "expected_improvement": 20.0,
                "implementation_cost": 4.0,
                "priority": 3,
                "conditions": ["cpu_usage > 75.0"],
                "actions": [
                    {"type": "optimize_algorithms", "focus": "hot_paths"},
                    {"type": "implement_caching", "level": "computation"},
                    {"type": "parallelize_operations", "max_workers": 4}
                ],
                "success_criteria": {"cpu_usage": 60.0}
            },
            {
                "strategy_id": "token_optimization",
                "strategy_type": "ai",
                "target_metric": "token_efficiency",
                "expected_improvement": 40.0,
                "implementation_cost": 1.0,
                "priority": 1,
                "conditions": ["token_efficiency < 0.8"],
                "actions": [
                    {"type": "compress_context", "ratio": 0.3},
                    {"type": "optimize_prompts", "strategy": "template"},
                    {"type": "implement_smart_caching", "ttl": 3600}
                ],
                "success_criteria": {"token_efficiency": 0.9}
            }
        ]
        
        for strategy_data in strategies:
            strategy = OptimizationStrategy(
                strategy_id=strategy_data["strategy_id"],
                strategy_type=strategy_data["strategy_type"],
                target_metric=strategy_data["target_metric"],
                expected_improvement=strategy_data["expected_improvement"],
                implementation_cost=strategy_data["implementation_cost"],
                priority=strategy_data["priority"],
                conditions=strategy_data["conditions"],
                actions=strategy_data["actions"],
                success_criteria=strategy_data["success_criteria"]
            )
            
            self.optimization_strategies[strategy.strategy_id] = strategy
    
    def _get_default_metrics(self) -> PerformanceMetrics:
        """Retorna m√©tricas por defecto en caso de error"""
        
        return PerformanceMetrics(
            timestamp=datetime.now(),
            cpu_usage=50.0,
            memory_usage=60.0,
            disk_io={},
            network_io={},
            response_time=3.0,
            throughput=80.0,
            error_rate=0.02,
            cache_hit_rate=0.75,
            token_efficiency=0.8
        )
    
    def _load_configuration(self):
        """Carga configuraci√≥n desde archivo"""
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                
                self.optimization_config.update(config.get("optimization_config", {}))
                self.optimization_stats.update(config.get("optimization_stats", {}))
                
                self.logger.info("‚öôÔ∏è Configuraci√≥n cargada")
                
            except Exception as e:
                self.logger.error(f"Error cargando configuraci√≥n: {e}")
    
    def save_configuration(self):
        """Guarda configuraci√≥n actual"""
        
        try:
            config = {
                "optimization_config": self.optimization_config,
                "optimization_stats": self.optimization_stats,
                "last_updated": datetime.now().isoformat()
            }
            
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(config, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.debug("üíæ Configuraci√≥n guardada")
            
        except Exception as e:
            self.logger.error(f"Error guardando configuraci√≥n: {e}")
    
    def get_system_status(self) -> Dict[str, Any]:
        """Obtiene el estado actual del optimizador"""
        
        return {
            "monitoring_active": self.monitoring_active,
            "current_metrics": asdict(self.current_metrics) if self.current_metrics else None,
            "metrics_history_size": len(self.metrics_history),
            "optimization_strategies": len(self.optimization_strategies),
            "optimization_stats": self.optimization_stats,
            "system_health": self._calculate_performance_score(),
            "auto_optimization_enabled": self.optimization_config["auto_optimization"]
        }

def main():
    """Funci√≥n principal para testing"""
    optimizer = PerformanceOptimizer()
    
    # Recolectar m√©tricas
    metrics = optimizer.collect_metrics()
    print(f"üìä M√©tricas actuales: CPU {metrics.cpu_usage:.1f}%, RAM {metrics.memory_usage:.1f}%")
    
    # Analizar rendimiento
    analysis = optimizer.analyze_performance(time_window_minutes=5)
    print(f"üìà An√°lisis: Salud del sistema {analysis.get('system_health_score', 0):.2f}")
    
    # Optimizar rendimiento
    optimization = optimizer.optimize_performance()
    print(f"‚ö° Optimizaci√≥n: {optimization.get('optimizations_applied', 0)} estrategias aplicadas")
    
    # Obtener insights
    insights = optimizer.get_optimization_insights()
    print(f"\nüéØ Insights del Sistema:")
    print(json.dumps(insights, indent=2, ensure_ascii=False, default=str))
    
    # Guardar configuraci√≥n
    optimizer.save_configuration()
    
    # Detener monitoreo
    optimizer.stop_monitoring()

if __name__ == "__main__":
    main()